{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"/home/ubuntu/rankability_toolbox\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyrankability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "D=np.array([[0,0,0,0,1,19,0,0],\n",
    "            [7,0,21,24,23,29,0,0],\n",
    "            [20,0,0,14,0,18,7,11],\n",
    "            [5,0,0,0,3,21,0,0],\n",
    "            [0,0,7,0,0,30,0,32],\n",
    "            [0,0,0,0,0,0,0,3],\n",
    "            [6,3,0,45,22,38,0,0],\n",
    "            [3,14,0,14,0,0,14,0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0,  0,  1, 19,  0,  0],\n",
       "       [ 7,  0, 21, 24, 23, 29,  0,  0],\n",
       "       [20,  0,  0, 14,  0, 18,  7, 11],\n",
       "       [ 5,  0,  0,  0,  3, 21,  0,  0],\n",
       "       [ 0,  0,  7,  0,  0, 30,  0, 32],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  3],\n",
       "       [ 6,  3,  0, 45, 22, 38,  0,  0],\n",
       "       [ 3, 14,  0, 14,  0,  0, 14,  0]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exhaustive approach for small D where number of items <= 10**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(83, {'P': [(5, 0, 3, 4, 7, 2, 1, 6), (5, 0, 3, 4, 7, 2, 6, 1)]})"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyrankability.hillside.objective_count_exhaustive(D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interger programming solver with constraint relaxation (default is not to search for P)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(83, {'P': []})"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k,details = pyrankability.hillside.count(D)\n",
    "k,details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interger programming solver with constraint relaxation with search for P.**\n",
    "\n",
    "Two parameters control the search for P. The first is max_solutions which controls the PoolSearch that Gurobi uses. It is not guranteed to find ``max_solution`` unique solutions. For this reason, we permute the D matrix which allows us to find multiple unique solutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1\n",
      "Number of new solutions 1\n",
      "Iteration 2\n",
      "Number of new solutions 0\n",
      "Iteration 3\n",
      "Number of new solutions 0\n",
      "Iteration 4\n",
      "Number of new solutions 1\n",
      "Iteration 5\n",
      "Number of new solutions 0\n",
      "Iteration 6\n",
      "Number of new solutions 0\n",
      "Iteration 7\n",
      "Number of new solutions 0\n",
      "Iteration 8\n",
      "Number of new solutions 0\n",
      "Iteration 9\n",
      "Number of new solutions 0\n",
      "Iteration 10\n",
      "Number of new solutions 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(83, {'P': [(5, 0, 3, 4, 7, 2, 6, 1), (5, 0, 3, 4, 7, 2, 1, 6)]})"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k,details = pyrankability.hillside.count(D,max_solutions=10,iterations=10)\n",
    "k,details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D=np.array([[0,0,0,18,12,0,35,0,0],\n",
    "            [21,0,10,3,0,0,41,0,14],\n",
    "            [18,0,0,10,0,0,4,4,8],\n",
    "            [0,0,0,0,23,0,2,4,3],\n",
    "            [0,21,20,0,0,0,0,9,13],\n",
    "            [38,1,27,21,3,0,48,3,14],\n",
    "            [0,0,0,0,3,0,0,0,0],\n",
    "            [3,7,0,0,0,0,10,0,30],\n",
    "            [1,0,0,0,0,0,25,0,0]])\n",
    "D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k,details = pyrankability.hillside.count_lp(D)\n",
    "k,details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "D = pd.read_csv(\"~/rankabilitylib-data/college_football/MBB/PatriotLeague/2008d1Matrix.csv\",header=None).values\n",
    "D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k,details = pyrankability.hillside.count_lp(D)\n",
    "k,details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyrankability.hillside.objective_count_exhaustive(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[1,2,3][::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for perm in P:\n",
    "    pyrankability.hillside.objective_count_perm(D,perm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0., 63.,  9., 19.,  0.,  2.,  4., 15.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0., 20.],\n",
       "       [31., 31.,  0.,  3., 20., 73.,  2., 11.],\n",
       "       [10., 11.,  0.,  0.,  0.,  9.,  7.,  5.],\n",
       "       [33., 88., 15., 23.,  0., 38., 26., 25.],\n",
       "       [ 4., 20.,  0.,  0.,  0.,  0.,  5., 10.],\n",
       "       [ 3., 23.,  3., 27.,  0.,  8.,  0.,  5.],\n",
       "       [ 0., 15.,  4., 11.,  0., 19.,  1.,  0.]])"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "D = pd.read_csv(\"~/rankabilitylib-data/college_football/MBB/PatriotLeague/2005d1Matrix.csv\",header=None).values\n",
    "D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(91,\n",
       " {'x': array([[1.00000000e+00, 1.00000000e+00, 3.30584066e-01, 6.69893525e-01,\n",
       "          1.33617885e-14, 1.00000000e+00, 5.05431451e-01, 1.00000000e+00],\n",
       "         [5.55111512e-15, 1.00000000e+00, 2.14642654e-15, 1.35423839e-14,\n",
       "          1.94325240e-15, 2.28347095e-13, 7.64506498e-15, 2.41123823e-14],\n",
       "         [6.69415934e-01, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "          8.82380902e-14, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00],\n",
       "         [3.30106475e-01, 1.00000000e+00, 9.65894031e-15, 1.00000000e+00,\n",
       "          1.23883055e-14, 1.00000000e+00, 9.06915755e-14, 1.00000000e+00],\n",
       "         [1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "          1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00],\n",
       "         [3.75255382e-14, 1.00000000e+00, 6.99440506e-15, 9.54791801e-14,\n",
       "          1.66533454e-15, 1.00000000e+00, 6.39028527e-14, 2.83296113e-12],\n",
       "         [4.94568549e-01, 1.00000000e+00, 5.09592368e-14, 1.00000000e+00,\n",
       "          1.48769885e-14, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00],\n",
       "         [1.50990331e-14, 1.00000000e+00, 9.99200722e-15, 3.68594044e-14,\n",
       "          2.88657986e-15, 1.00000000e+00, 1.15685239e-13, 1.00000000e+00]]),\n",
       "  'c': array([[ 0.,  1.,  7.,  7., 12.,  4.,  7.,  4.],\n",
       "         [11.,  0., 13., 10., 14.,  8., 12., 12.],\n",
       "         [ 7.,  1.,  0.,  1., 10.,  2.,  5.,  3.],\n",
       "         [ 7.,  2., 11.,  0., 11.,  4.,  7.,  7.],\n",
       "         [ 0.,  0.,  3.,  1.,  0.,  0.,  2.,  1.],\n",
       "         [10.,  3., 11.,  7., 13.,  0.,  9.,  8.],\n",
       "         [ 7.,  1., 10.,  6., 11.,  5.,  0.,  6.],\n",
       "         [ 9.,  2., 13.,  8., 13.,  7.,  9.,  0.]]),\n",
       "  'model': <gurobi.Model Continuous instance rankability_hillside_count: 392 constrs, 64 vars, Parameter changes: Method=2, Crossover=0, LogFile=gurobi.log, CSIdleTimeout=1800, OutputFlag=0>,\n",
       "  'P': [[1, 5, 7, 3, 6, 0, 2, 4],\n",
       "   [1, 5, 7, 3, 6, 2, 0, 4],\n",
       "   [1, 5, 7, 0, 3, 6, 2, 4],\n",
       "   [1, 5, 7, 3, 0, 6, 2, 4]]})"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k,details = pyrankability.hillside.count_lp(D)\n",
    "k,details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyrankability.hillside.objective_count_exhaustive(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!which python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LETOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyltr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/panderson/MQ2008-list/Fold1/train.txt') as trainfile, \\\n",
    "        open('/home/panderson/MQ2008-list/Fold1/vali.txt') as valifile, \\\n",
    "        open('/home/panderson/MQ2008-list/Fold1/test.txt') as evalfile:\n",
    "    TX, Ty, Tqids, _ = pyltr.data.letor.read_dataset(trainfile)\n",
    "    VX, Vy, Vqids, _ = pyltr.data.letor.read_dataset(valifile)\n",
    "    EX, Ey, Eqids, _ = pyltr.data.letor.read_dataset(evalfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "471"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique(Tqids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_by_query_id(X,y,qids,sample_method=None):\n",
    "    by_query_id = {}\n",
    "    for qid in np.unique(qids):\n",
    "        ixs = np.where(qids == qid)[0]\n",
    "        by_query_id[qid] = {}\n",
    "        if sample_method is None:\n",
    "            by_query_id[qid]['X'] = X[ixs,:]\n",
    "            by_query_id[qid]['y'] = y[ixs]\n",
    "        elif sample_method == 'easy 10':\n",
    "            size = pyrankability.common.len_chunks(ixs,10)\n",
    "            ixs = [v[-1] for v in pyrankability.common.chunks(ixs,size)]\n",
    "            by_query_id[qid]['X'] = X[ixs,:]\n",
    "            by_query_id[qid]['y'] = y[ixs]\n",
    "        elif sample_method == 'random 10':\n",
    "            ixs = np.random.randint(0, high=len(ixs)-1, size=10)\n",
    "            by_query_id[qid]['X'] = X[ixs,:]\n",
    "            by_query_id[qid]['y'] = y[ixs]\n",
    "        elif sample_method == 'hard 10':\n",
    "            #size = pyrankability.common.len_chunks(ixs,10)\n",
    "            ixs = ixs[-10:] #[v[-1] for v in pyrankability.common.chunks(ixs,size)]\n",
    "            by_query_id[qid]['X'] = X[ixs,:]\n",
    "            by_query_id[qid]['y'] = y[ixs]\n",
    "    return by_query_id\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tby_query_id = process_by_query_id(TX,Ty,Tqids,sample_method='random 10')\n",
    "Vby_query_id = process_by_query_id(VX,Vy,Vqids,sample_method='random 10')\n",
    "Eby_query_id = process_by_query_id(EX,Ey,Eqids,sample_method='random 10')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Put things back in order for the algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine(by_query_id):\n",
    "    Xs = []\n",
    "    qids = []\n",
    "    ys = []\n",
    "    for key in by_query_id.keys():\n",
    "        Xs.append(by_query_id[key][\"X\"])\n",
    "        ys.append(by_query_id[key][\"y\"])\n",
    "        qids.append([key for i in range(len(by_query_id[key][\"y\"]))])\n",
    "    return np.vstack(Xs), np.hstack(ys), np.hstack(qids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Iter  Train score  OOB Improve    Remaining                           Monitor Output \n",
      "    1       0.4696       1.4620       16.53m      C:      0.1866 B:      0.1866 S:  0\n",
      "    2       0.4839       0.0267       16.48m      C:      0.1928 B:      0.1928 S:  0\n",
      "    3       0.5228       0.0512       16.48m      C:      0.2978 B:      0.2978 S:  0\n",
      "    4       0.5560       0.0092       16.47m      C:      0.3805 B:      0.3805 S:  0\n",
      "    5       0.5656       0.0102       16.50m      C:      0.4130 B:      0.4130 S:  0\n",
      "    6       0.5754      -0.0002       16.47m      C:      0.4159 B:      0.4159 S:  0\n",
      "    7       0.5978       0.0230       16.51m      C:      0.4272 B:      0.4272 S:  0\n",
      "    8       0.5938       0.0200       16.50m      C:      0.4558 B:      0.4558 S:  0\n",
      "    9       0.6171       0.0011       16.47m      C:      0.4645 B:      0.4645 S:  0\n",
      "   10       0.6185       0.0017       16.44m      C:      0.4733 B:      0.4733 S:  0\n",
      "   15       0.6080      -0.0008       16.40m      C:      0.4708 B:      0.4742 S:  2\n",
      "   20       0.6391       0.0000       16.35m      C:      0.4804 B:      0.4810 S:  1\n",
      "   25       0.6367      -0.0002       16.23m      C:      0.4926 B:      0.4926 S:  0\n",
      "   30       0.6598       0.0068       16.12m      C:      0.5062 B:      0.5062 S:  1\n",
      "   35       0.6784       0.0015       16.03m      C:      0.5138 B:      0.5138 S:  0\n",
      "   40       0.6865       0.0019       15.97m      C:      0.5130 B:      0.5155 S:  4\n",
      "   45       0.6668       0.0006       15.89m      C:      0.5118 B:      0.5155 S:  9\n",
      "   50       0.6824       0.0021       15.81m      C:      0.5090 B:      0.5155 S: 14\n",
      "   60       0.6859      -0.0008       15.63m      C:      0.5093 B:      0.5155 S: 24\n",
      "   70       0.6856       0.0002       15.46m      C:      0.5062 B:      0.5155 S: 34\n",
      "   80       0.6977       0.0002       15.27m      C:      0.5107 B:      0.5155 S: 44\n",
      "   90       0.6852      -0.0000       15.12m      C:      0.5101 B:      0.5155 S: 54\n",
      "  100       0.6996      -0.0002       14.98m      C:      0.5113 B:      0.5155 S: 64\n",
      "  120       0.7215       0.0002       14.68m      C:      0.5070 B:      0.5155 S: 84\n",
      "  140       0.7195       0.0006       14.36m      C:      0.5104 B:      0.5155 S:104\n",
      "  160       0.7266       0.0002       14.02m      C:      0.5064 B:      0.5155 S:124\n",
      "  180       0.7277      -0.0009       13.69m      C:      0.5042 B:      0.5155 S:144\n",
      "  200       0.7308      -0.0002       13.36m      C:      0.5039 B:      0.5155 S:164\n",
      "  220       0.7364       0.0000       13.02m      C:      0.5039 B:      0.5155 S:184\n",
      "  240       0.7531       0.0004       12.67m      C:      0.5028 B:      0.5155 S:204\n",
      "  260       0.7491      -0.0006       12.32m      C:      0.4979 B:      0.5155 S:224\n",
      "  280       0.7487       0.0008       11.98m      C:      0.4982 B:      0.5155 S:244\n",
      "Early termination at iteration  285\n"
     ]
    }
   ],
   "source": [
    "def run():\n",
    "    TX, Ty, Tqids = combine(Tby_query_id)\n",
    "    VX, Vy, Vqids = combine(Vby_query_id)\n",
    "    #EX, Ey, Eqids = combine(Eby_query_id)\n",
    "    \n",
    "    metric = pyltr.metrics.KendallTau()\n",
    "\n",
    "    # Only needed if you want to perform validation (early stopping & trimming)\n",
    "    monitor = pyltr.models.monitors.ValidationMonitor(\n",
    "        VX, Vy, Vqids, metric=metric, stop_after=250)\n",
    "\n",
    "    model = pyltr.models.LambdaMART(\n",
    "        metric=metric,\n",
    "        n_estimators=1000,\n",
    "        learning_rate=0.02,\n",
    "        max_features=0.5,\n",
    "        query_subsample=0.5,\n",
    "        max_leaf_nodes=10,\n",
    "        min_samples_leaf=64,\n",
    "        verbose=1,\n",
    "    )\n",
    "\n",
    "    model.fit(TX, Ty, Tqids, monitor=monitor)\n",
    "    return model\n",
    "\n",
    "model = run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "\n",
    "def run():\n",
    "    scores = []\n",
    "    for qid in Eby_query_id.keys():\n",
    "        preds = model.predict(Eby_query_id[qid][\"X\"])\n",
    "        scores.append(scipy.stats.kendalltau(Eby_query_id[qid][\"y\"],preds))\n",
    "    return scores\n",
    "scores = run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[KendalltauResult(correlation=0.6137949055234262, pvalue=0.014912049655215961),\n",
       " KendalltauResult(correlation=0.6, pvalue=0.01573722226631101),\n",
       " KendalltauResult(correlation=0.4666666666666666, pvalue=0.06034053291564658),\n",
       " KendalltauResult(correlation=0.8666666666666666, pvalue=0.00048616407497926973),\n",
       " KendalltauResult(correlation=0.8222222222222221, pvalue=0.0009350263526396277),\n",
       " KendalltauResult(correlation=0.7333333333333333, pvalue=0.0031612220209069567),\n",
       " KendalltauResult(correlation=0.7777777777777777, pvalue=0.001745118699528905),\n",
       " KendalltauResult(correlation=0.6444444444444444, pvalue=0.00949109605344092),\n",
       " KendalltauResult(correlation=0.8539864924534399, pvalue=0.0006436975254696877),\n",
       " KendalltauResult(correlation=0.8222222222222221, pvalue=0.0009350263526396277)]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct D matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[KendalltauResult(correlation=0.18249212097065884, pvalue=0.0),\n",
       " KendalltauResult(correlation=0.11944076654429298, pvalue=0.0),\n",
       " KendalltauResult(correlation=0.10168120756846151, pvalue=0.0),\n",
       " KendalltauResult(correlation=0.10471621984140529, pvalue=0.0),\n",
       " KendalltauResult(correlation=0.18540912821073338, pvalue=0.0),\n",
       " KendalltauResult(correlation=nan, pvalue=nan),\n",
       " KendalltauResult(correlation=nan, pvalue=nan),\n",
       " KendalltauResult(correlation=nan, pvalue=nan),\n",
       " KendalltauResult(correlation=nan, pvalue=nan),\n",
       " KendalltauResult(correlation=nan, pvalue=nan),\n",
       " KendalltauResult(correlation=0.11247021080336579, pvalue=0.0),\n",
       " KendalltauResult(correlation=0.12130178955305186, pvalue=0.0),\n",
       " KendalltauResult(correlation=0.10582693593983282, pvalue=0.0),\n",
       " KendalltauResult(correlation=0.10534532684174848, pvalue=0.0),\n",
       " KendalltauResult(correlation=0.1138518758927467, pvalue=0.0),\n",
       " KendalltauResult(correlation=0.021197130736137607, pvalue=8.608815897072821e-121),\n",
       " KendalltauResult(correlation=0.023881252429787295, pvalue=6.144755714592187e-149),\n",
       " KendalltauResult(correlation=0.005117156095286586, pvalue=3.759537238208439e-08),\n",
       " KendalltauResult(correlation=-0.01495497031408703, pvalue=1.2440974324930256e-60),\n",
       " KendalltauResult(correlation=0.021442644944350255, pvalue=1.4646859067404723e-123),\n",
       " KendalltauResult(correlation=0.4604048790109265, pvalue=0.0),\n",
       " KendalltauResult(correlation=0.49211723374679606, pvalue=0.0),\n",
       " KendalltauResult(correlation=0.51989489441912, pvalue=0.0),\n",
       " KendalltauResult(correlation=0.5032430227251642, pvalue=0.0),\n",
       " KendalltauResult(correlation=0.12309742557950372, pvalue=0.0),\n",
       " KendalltauResult(correlation=0.12663392698176648, pvalue=0.0),\n",
       " KendalltauResult(correlation=0.1264192372975882, pvalue=0.0),\n",
       " KendalltauResult(correlation=0.1274941716145941, pvalue=0.0),\n",
       " KendalltauResult(correlation=0.10283066508417033, pvalue=0.0),\n",
       " KendalltauResult(correlation=0.10946783592091565, pvalue=0.0),\n",
       " KendalltauResult(correlation=0.10952520669956065, pvalue=0.0),\n",
       " KendalltauResult(correlation=0.10958193309181767, pvalue=0.0),\n",
       " KendalltauResult(correlation=0.10675748205945416, pvalue=0.0),\n",
       " KendalltauResult(correlation=0.10881318057207953, pvalue=0.0),\n",
       " KendalltauResult(correlation=0.10846220144691679, pvalue=0.0),\n",
       " KendalltauResult(correlation=0.10871740738188915, pvalue=0.0),\n",
       " KendalltauResult(correlation=0.45673084440907724, pvalue=0.0),\n",
       " KendalltauResult(correlation=0.5003591552626135, pvalue=0.0),\n",
       " KendalltauResult(correlation=0.5273295816692292, pvalue=0.0),\n",
       " KendalltauResult(correlation=0.5072619035000512, pvalue=0.0),\n",
       " KendalltauResult(correlation=-0.02894975047912221, pvalue=3.2444008635426376e-212),\n",
       " KendalltauResult(correlation=-0.02001729845330399, pvalue=6.6447105538133396e-108),\n",
       " KendalltauResult(correlation=nan, pvalue=nan),\n",
       " KendalltauResult(correlation=0.003418659555794849, pvalue=0.0001976091743612728),\n",
       " KendalltauResult(correlation=0.003398605808210408, pvalue=0.00020909525620179772),\n",
       " KendalltauResult(correlation=0.04254342515899703, pvalue=0.0)]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrs = []\n",
    "for i in range(TX.shape[1]):\n",
    "    corrs.append(scipy.stats.kendalltau(TX[:,i],Ty,nan_policy='omit'))\n",
    "corrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "\n",
    "def compute_D(X,correlations):\n",
    "    #correlations = np.array([c.correlation for c in corrs])\n",
    "    ixs = np.where(~np.isnan(correlations))[0]\n",
    "    #ixs = np.array([38,39,22,23])\n",
    "    #pos_direction = np.where(np.array(correlations)[ixs] > 0)[0]\n",
    "    #neg_direction = np.where(np.array(correlations)[ixs] < 0)[0]\n",
    "    #Xpos = -X[:,ixs[pos_direction]]\n",
    "    #Xneg = X[:,ixs[neg_direction]]\n",
    "    #Xnew = np.hstack([Xpos,Xneg])\n",
    "    Xnew = X[:,ixs]\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(Xnew)\n",
    "    Xnew_scaled = scaler.transform(Xnew)\n",
    "    n = Xnew_scaled.shape[0]\n",
    "    K = RBF()\n",
    "    D = K(Xnew_scaled)\n",
    "    for j in range(n):\n",
    "        D[j,j] = 0\n",
    "    mx = np.max(D)\n",
    "    D = D/mx*100\n",
    "    \n",
    "    #D = pd.DataFrame(Xnew_scaled).corr().values\n",
    "    for i in range(n):\n",
    "        for j in range(i+1,n):\n",
    "            greater_ij = sum(Xnew_scaled[i,:] > Xnew_scaled[j,:])\n",
    "            if greater_ij >= Xnew_scaled.shape[1]/2:\n",
    "                D[j,i] = 0\n",
    "            else:\n",
    "                D[i,j] = 0\n",
    "    \"\"\"\n",
    "    D = np.zeros((n,n))\n",
    "    for i in range(n):\n",
    "        for j in range(i+1,n):\n",
    "            game_scores = []\n",
    "            for c in range(Xnew_scaled.shape[1]):\n",
    "                game_scores.append(Xnew_scaled[i,c] - Xnew_scaled[j,c])\n",
    "                #if sc < 0:\n",
    "                #    D[j,i] += -1*sc\n",
    "                #else:\n",
    "                #    D[i,j] += sc\n",
    "            avg = np.median(game_scores)\n",
    "            #avg = len(np.where(np.array(game_scores) > 0)[0])-len(game_scores)/2\n",
    "            if avg < 0:\n",
    "                D[j,i] = -1*avg\n",
    "            else:\n",
    "                D[i,j] = avg\"\"\"\n",
    "    return D\n",
    "            \n",
    "Ds = []\n",
    "for qid in Eby_query_id.keys():\n",
    "    Ds.append(compute_D(Eby_query_id[qid][\"X\"],[c.correlation for c in corrs]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "def fit_X_D_transformer(Tby_query_id):\n",
    "    dXs = []\n",
    "    dys = []\n",
    "    for qid in Tby_query_id.keys():\n",
    "        X = pd.DataFrame(Tby_query_id[qid][\"X\"]).fillna(0)\n",
    "        for i in range(X.shape[0]):\n",
    "            for j in range(i+1,X.shape[0]):\n",
    "                dXs.append((X.iloc[i,:]-X.iloc[j,:]).values)\n",
    "                dys.append(Tby_query_id[qid][\"y\"][i]-Tby_query_id[qid][\"y\"][j])\n",
    "    clf = RandomForestRegressor(n_estimators=100,random_state=0)\n",
    "    clf.fit(np.vstack(dXs),np.vstack(dys))\n",
    "    return clf\n",
    "    \n",
    "def compute_D(X,clf):\n",
    "    D = np.zeros((X.shape[0],X.shape[0]))\n",
    "    X = pd.DataFrame(X).fillna(0)\n",
    "    for i in range(X.shape[0]):\n",
    "        for j in range(i+1,X.shape[0]):\n",
    "            dX = (X.iloc[i,:]-X.iloc[j,:]).values\n",
    "            dy = clf.predict(dX.reshape(1,-1))\n",
    "            if dy > 0:\n",
    "                D[i,j] = dy\n",
    "            else:\n",
    "                D[j,i] = -dy\n",
    "    return D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/panderson/env/lib/python3.6/site-packages/ipykernel_launcher.py:13: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "clf = fit_X_D_transformer(Tby_query_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ds = []\n",
    "for qid in Eby_query_id.keys():\n",
    "    Ds.append(compute_D(Eby_query_id[qid][\"X\"],clf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.        ,   0.        ,   0.        ,   0.        ,\n",
       "          0.        ,   0.        ,   0.        ,   0.        ,\n",
       "          0.        ,   0.        ],\n",
       "       [656.91      ,   0.        ,   0.        ,   0.        ,\n",
       "        430.83      , 500.8       , 222.53      ,   0.        ,\n",
       "          0.        ,   0.        ],\n",
       "       [854.9       , 511.7       ,   0.        , 243.61      ,\n",
       "        565.73      , 859.17      , 403.7       , 361.5       ,\n",
       "          0.        , 509.19      ],\n",
       "       [894.21      , 230.31      ,   0.        ,   0.        ,\n",
       "        601.54      , 832.78      , 591.34      , 186.8       ,\n",
       "          0.        , 403.49      ],\n",
       "       [461.37      ,   0.        ,   0.        ,   0.        ,\n",
       "          0.        , 496.59      ,   0.        ,   0.        ,\n",
       "          0.        ,   0.        ],\n",
       "       [ 15.95733333,   0.        ,   0.        ,   0.        ,\n",
       "          0.        ,   0.        ,   0.        ,   0.        ,\n",
       "          0.        ,   0.        ],\n",
       "       [505.74      ,   0.        ,   0.        ,   0.        ,\n",
       "        240.82      , 498.13      ,   0.        ,   0.        ,\n",
       "          0.        ,   0.        ],\n",
       "       [712.54      , 132.25      ,   0.        ,   0.        ,\n",
       "        401.55      , 732.77      , 346.85      ,   0.        ,\n",
       "          0.        ,   0.        ],\n",
       "       [829.38      , 390.9       ,  41.37705128, 263.91      ,\n",
       "        662.44      , 840.27      , 534.5       , 322.83      ,\n",
       "          0.        , 546.96      ],\n",
       "       [729.04      , 177.93      ,   0.        ,   0.        ,\n",
       "        487.89      , 756.56      , 334.15      ,  54.78      ,\n",
       "          0.        ,   0.        ]])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-190-c30662c63491>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mdetails_results\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdetails\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mincluded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mk_worst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpyrankability\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhillside\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjective_count_perm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdetails\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"P\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mk_worst_results\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk_worst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk_worst\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdetails\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"P\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "k_results = []\n",
    "details_results = []\n",
    "exclude = []#13,16,30,83,84,88,92,94]\n",
    "included = []\n",
    "k_worst_results = []\n",
    "for i,D in enumerate(Ds):\n",
    "    #print(i)\n",
    "    #print(pyrankability.hillside.objective_count_exhaustive(D))\n",
    "    if i in exclude:\n",
    "        continue\n",
    "    k,details = pyrankability.hillside.count_lp(D)\n",
    "    k_results.append(k)\n",
    "    details_results.append(details)\n",
    "    included.append(i)\n",
    "    k_worst = pyrankability.hillside.objective_count_perm(D,details[\"P\"][0][::-1])\n",
    "    k_worst_results.append(k_worst)\n",
    "    print(i,k,k_worst,len(details[\"P\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_ixs = np.argsort(k_results)\n",
    "max_ixs = np.argsort(-1*np.array(k_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7097897952421139, 23.4, 544.8)"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(compare_correlations)[min_ixs[:10]].mean(),np.array(k_results)[min_ixs[:10]].mean(),np.array(k_worst_results)[min_ixs[:10]].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6143699956904076, 73.1, 499.7)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(compare_correlations)[max_ixs[:10]].mean(),np.array(k_results)[max_ixs[:10]].mean(),np.array(k_worst_results)[max_ixs[:10]].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_ix = np.argmin(k_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_ix = np.argmax(k_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_ix = np.argmax(compare_correlations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.911111111111111, 0.4666666666666666)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores[min_ix].correlation,scores[max_ix].correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27, 96)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_results[min_ix],k_results[max_ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P_values[min_ix],P_values[max_ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, {'P': [(1, 8, 2, 7, 0, 6, 5, 3, 9, 4)]})"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyrankability.hillside.objective_count_exhaustive(Ds[min_ix])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(97, {'P': [(2, 8, 3, 9, 6, 1, 7, 0, 4, 5), (2, 8, 9, 3, 6, 1, 7, 0, 4, 5)]})"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyrankability.hillside.objective_count_exhaustive(Ds[max_ix])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_metric = []\n",
    "for ix in range(len(details_results)):\n",
    "    n=Ds[ix].shape[0]\n",
    "    r=np.zeros((n,n))\n",
    "    P = np.array(details_results[ix][\"P\"])\n",
    "    if len(P) == 0:\n",
    "        r_metric.append(0)\n",
    "        continue\n",
    "\n",
    "    for i in range(P.shape[0]):\n",
    "        for j in range(n):\n",
    "            r[P[i,j],j]=r[P[i,j],j]+1\n",
    "    r=r/P.shape[0]\n",
    "    r_metric.append(np.count_nonzero(r)) #np.std(r,axis=1)\n",
    "    #r_metric.append(np.mean(stdevs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>len_P</th>\n",
       "      <th>corr</th>\n",
       "      <th>k</th>\n",
       "      <th>r_metric</th>\n",
       "      <th>k_worst</th>\n",
       "      <th>kdiff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>len_P</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.023575</td>\n",
       "      <td>0.125242</td>\n",
       "      <td>0.991052</td>\n",
       "      <td>-0.105721</td>\n",
       "      <td>-0.123477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>corr</th>\n",
       "      <td>-0.023575</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.131638</td>\n",
       "      <td>-0.021240</td>\n",
       "      <td>0.130339</td>\n",
       "      <td>0.131853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k</th>\n",
       "      <td>0.125242</td>\n",
       "      <td>-0.131638</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.133279</td>\n",
       "      <td>-0.907497</td>\n",
       "      <td>-0.995836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r_metric</th>\n",
       "      <td>0.991052</td>\n",
       "      <td>-0.021240</td>\n",
       "      <td>0.133279</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.113702</td>\n",
       "      <td>-0.131378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k_worst</th>\n",
       "      <td>-0.105721</td>\n",
       "      <td>0.130339</td>\n",
       "      <td>-0.907497</td>\n",
       "      <td>-0.113702</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.912084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kdiff</th>\n",
       "      <td>-0.123477</td>\n",
       "      <td>0.131853</td>\n",
       "      <td>-0.995836</td>\n",
       "      <td>-0.131378</td>\n",
       "      <td>0.912084</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             len_P      corr         k  r_metric   k_worst     kdiff\n",
       "len_P     1.000000 -0.023575  0.125242  0.991052 -0.105721 -0.123477\n",
       "corr     -0.023575  1.000000 -0.131638 -0.021240  0.130339  0.131853\n",
       "k         0.125242 -0.131638  1.000000  0.133279 -0.907497 -0.995836\n",
       "r_metric  0.991052 -0.021240  0.133279  1.000000 -0.113702 -0.131378\n",
       "k_worst  -0.105721  0.130339 -0.907497 -0.113702  1.000000  0.912084\n",
       "kdiff    -0.123477  0.131853 -0.995836 -0.131378  0.912084  1.000000"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P_values = [len(details[\"P\"]) for details in details_results]\n",
    "compare_correlations = [scores[i].correlation for i in range(len(scores))]\n",
    "df = pd.DataFrame({\"len_P\":P_values,\"corr\":np.array(compare_correlations)[included],\"k\":k_results,\"r_metric\":r_metric,\"k_worst\":k_worst_results,\n",
    "                   \"kdiff\":(np.array(k_worst_results)-np.array(k_results))/(np.array(k_worst_results)+np.array(k_results))})\n",
    "df.corr(method=\"kendall\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.15626951237157105, 0.05140376347143358)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scipy.stats.pearsonr(df[\"k\"],df[\"corr\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KendalltauResult(correlation=-0.1316376880159101, pvalue=0.017682629859099176)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scipy.stats.kendalltau(df[\"k\"],df[\"corr\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
